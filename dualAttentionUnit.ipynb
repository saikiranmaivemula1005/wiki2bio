{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dualAttentionUnit.ipynb","provenance":[],"authorship_tag":"ABX9TyP93RGN2xYbnlYpHhNnD/gm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Trar3rahvTe0","colab_type":"code","colab":{}},"source":["#!/usr/bin/env python\n","# -*- coding: utf-8 -*-\n","# @Time    : 17-5-12 下午10:47\n","# @Author  : Tianyu Liu\n","\n","import tensorflow as tf\n","import pickle\n","\n","\n","class dualAttentionWrapper(object):\n","    def __init__(self, hidden_size, input_size, field_size, hs, fds, scope_name):\n","        self.hs = tf.transpose(hs, [1,0,2])  # input_len * batch * input_size\n","        self.fds = tf.transpose(fds, [1,0,2])\n","        self.hidden_size = hidden_size\n","        self.input_size = input_size\n","        self.scope_name = scope_name\n","        self.params = {}\n","\n","        with tf.variable_scope(scope_name):\n","            self.Wh = tf.get_variable('Wh', [input_size, hidden_size])\n","            self.bh = tf.get_variable('bh', [hidden_size])\n","            self.Ws = tf.get_variable('Ws', [input_size, hidden_size])\n","            self.bs = tf.get_variable('bs', [hidden_size])\n","            self.Wo = tf.get_variable('Wo', [2*input_size, hidden_size])\n","            self.bo = tf.get_variable('bo', [hidden_size])\n","            self.Wf = tf.get_variable('Wf', [field_size, hidden_size])\n","            self.bf = tf.get_variable('bf', [hidden_size])\n","            self.Wr = tf.get_variable('Wr', [input_size, hidden_size])\n","            self.br = tf.get_variable('br', [hidden_size])\n","\n","        self.params.update({'Wh': self.Wh, 'Ws': self.Ws, 'Wo': self.Wo,\n","                            'bh': self.bh, 'bs': self.bs, 'bo': self.bo,\n","                            'Wf': self.Wf, 'Wr': self.Wr, \n","                            'bf': self.bf, 'br': self.br})\n","\n","        hs2d = tf.reshape(self.hs, [-1, input_size])\n","        phi_hs2d = tf.tanh(tf.nn.xw_plus_b(hs2d, self.Wh, self.bh))\n","        self.phi_hs = tf.reshape(phi_hs2d, tf.shape(self.hs))\n","        fds2d = tf.reshape(self.fds, [-1, field_size])\n","        phi_fds2d = tf.tanh(tf.nn.xw_plus_b(fds2d, self.Wf, self.bf))\n","        self.phi_fds = tf.reshape(phi_fds2d, tf.shape(self.hs))\n","\n","    def __call__(self, x, coverage = None, finished = None):\n","        gamma_h = tf.tanh(tf.nn.xw_plus_b(x, self.Ws, self.bs))  # batch * hidden_size\n","        alpha_h = tf.tanh(tf.nn.xw_plus_b(x, self.Wr, self.br))\n","        fd_weights = tf.reduce_sum(self.phi_fds * alpha_h, reduction_indices=2, keep_dims=True)\n","        fd_weights = tf.exp(fd_weights - tf.reduce_max(fd_weights, reduction_indices=0, keep_dims=True))\n","        fd_weights = tf.divide(fd_weights, (1e-6 + tf.reduce_sum(fd_weights, reduction_indices=0, keep_dims=True)))\n","        \n","        \n","        weights = tf.reduce_sum(self.phi_hs * gamma_h, reduction_indices=2, keep_dims=True)  # input_len * batch\n","        weights = tf.exp(weights - tf.reduce_max(weights, reduction_indices=0, keep_dims=True))\n","        weights = tf.divide(weights, (1e-6 + tf.reduce_sum(weights, reduction_indices=0, keep_dims=True)))\n","        weights = tf.divide(weights * fd_weights, (1e-6 + tf.reduce_sum(weights * fd_weights, reduction_indices=0, keep_dims=True)))\n","        \n","        context = tf.reduce_sum(self.hs * weights, reduction_indices=0)  # batch * input_size\n","        out = tf.tanh(tf.nn.xw_plus_b(tf.concat([context, x], -1), self.Wo, self.bo))\n","\n","        if finished is not None:\n","            out = tf.where(finished, tf.zeros_like(out), out)\n","        return out, weights\n","\n","    def save(self, path):\n","        param_values = {}\n","        for param in self.params:\n","            param_values[param] = self.params[param].eval()\n","        with open(path, 'wb') as f:\n","            pickle.dump(param_values, f, True)\n","\n","    def load(self, path):\n","        param_values = pickle.load(open(path, 'rb'))\n","        for param in param_values:\n","            self.params[param].load(param_values[param])"],"execution_count":0,"outputs":[]}]}