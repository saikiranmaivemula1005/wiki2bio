{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SeqUnit.ipynb","provenance":[],"authorship_tag":"ABX9TyN67+NHG3pN5dtnqAtQ545I"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"3YEekiQ5sT2A","colab_type":"code","outputId":"2277b999-60cb-474a-9011-d9904126237d","executionInfo":{"status":"error","timestamp":1592287492913,"user_tz":-330,"elapsed":4089,"user":{"displayName":"Sai Kiranmai Vemula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYzW8_0OHzEcN1utqXxk21oTbCtmfOp4zz4HpDFw=s64","userId":"15355417407830951385"}},"colab":{"base_uri":"https://localhost:8080/","height":362}},"source":["#!/usr/bin/env python\n","# -*- coding: utf-8 -*-\n","# @Time    : 17-4-27 下午8:37\n","# @Author  : Tianyu Liu\n","\n","import tensorflow as tf\n","import pickle\n","from AttentionUnit import AttentionWrapper\n","from dualAttentionUnit import dualAttentionWrapper\n","from LstmUnit import LstmUnit\n","from fgateLstmUnit import fgateLstmUnit\n","from OutputUnit import OutputUnit\n","\n","\n","class SeqUnit(object):\n","    def __init__(self, batch_size, hidden_size, emb_size, field_size, pos_size, source_vocab, field_vocab,\n","                 position_vocab, target_vocab, field_concat, position_concat, fgate_enc, dual_att,\n","                 encoder_add_pos, decoder_add_pos, learning_rate, scope_name, name, start_token=2, stop_token=2, max_length=150):\n","        '''\n","        batch_size, hidden_size, emb_size, field_size, pos_size: size of batch; hidden layer; word/field/position embedding\n","        source_vocab, target_vocab, field_vocab, position_vocab: vocabulary size of encoder words; decoder words; field types; position\n","        field_concat, position_concat: bool values, whether concat field/position embedding to word embedding for encoder inputs or not\n","        fgate_enc, dual_att: bool values, whether use field-gating / dual attention or not\n","        encoder_add_pos, decoder_add_pos: bool values, whether add position embedding to field-gating encoder / decoder with dual attention or not\n","        '''\n","        self.batch_size = batch_size\n","        self.hidden_size = hidden_size\n","        self.emb_size = emb_size\n","        self.field_size = field_size\n","        self.pos_size = pos_size\n","        self.uni_size = emb_size if not field_concat else emb_size+field_size\n","        self.uni_size = self.uni_size if not position_concat else self.uni_size+2*pos_size\n","        self.field_encoder_size = field_size if not encoder_add_pos else field_size+2*pos_size\n","        self.field_attention_size = field_size if not decoder_add_pos else field_size+2*pos_size\n","        self.source_vocab = source_vocab\n","        self.target_vocab = target_vocab\n","        self.field_vocab = field_vocab\n","        self.position_vocab = position_vocab\n","        self.grad_clip = 5.0\n","        self.start_token = start_token\n","        self.stop_token = stop_token\n","        self.max_length = max_length\n","        self.scope_name = scope_name\n","        self.name = name\n","        self.field_concat = field_concat\n","        self.position_concat = position_concat\n","        self.fgate_enc = fgate_enc\n","        self.dual_att = dual_att\n","        self.encoder_add_pos = encoder_add_pos\n","        self.decoder_add_pos = decoder_add_pos\n","\n","        self.units = {}\n","        self.params = {}\n","\n","        self.encoder_input = tf.placeholder(tf.int32, [None, None])\n","        self.encoder_field = tf.placeholder(tf.int32, [None, None])\n","        self.encoder_pos = tf.placeholder(tf.int32, [None, None])\n","        self.encoder_rpos = tf.placeholder(tf.int32, [None, None])\n","        self.decoder_input = tf.placeholder(tf.int32, [None, None])\n","        self.encoder_len = tf.placeholder(tf.int32, [None])\n","        self.decoder_len = tf.placeholder(tf.int32, [None])\n","        self.decoder_output = tf.placeholder(tf.int32, [None, None])\n","        self.enc_mask = tf.sign(tf.to_float(self.encoder_pos))\n","        with tf.variable_scope(scope_name):\n","            if self.fgate_enc:\n","                print('field-gated encoder LSTM')\n","                self.enc_lstm = fgateLstmUnit(self.hidden_size, self.uni_size, self.field_encoder_size, 'encoder_select')\n","            else:\n","                print('normal encoder LSTM')\n","                self.enc_lstm = LstmUnit(self.hidden_size, self.uni_size, 'encoder_lstm')\n","            self.dec_lstm = LstmUnit(self.hidden_size, self.emb_size, 'decoder_lstm')\n","            self.dec_out = OutputUnit(self.hidden_size, self.target_vocab, 'decoder_output')\n","\n","        self.units.update({'encoder_lstm': self.enc_lstm,'decoder_lstm': self.dec_lstm,\n","                           'decoder_output': self.dec_out})\n","\n","        # ======================================== embeddings ======================================== #\n","        with tf.device('/cpu:0'):\n","            with tf.variable_scope(scope_name):\n","                self.embedding = tf.get_variable('embedding', [self.source_vocab, self.emb_size])\n","                self.encoder_embed = tf.nn.embedding_lookup(self.embedding, self.encoder_input)\n","                self.decoder_embed = tf.nn.embedding_lookup(self.embedding, self.decoder_input)\n","                if self.field_concat or self.fgate_enc or self.encoder_add_pos or self.decoder_add_pos:\n","                    self.fembedding = tf.get_variable('fembedding', [self.field_vocab, self.field_size])\n","                    self.field_embed = tf.nn.embedding_lookup(self.fembedding, self.encoder_field)\n","                    self.field_pos_embed = self.field_embed\n","                    if self.field_concat:\n","                        self.encoder_embed = tf.concat([self.encoder_embed, self.field_embed], 2)\n","                if self.position_concat or self.encoder_add_pos or self.decoder_add_pos:\n","                    self.pembedding = tf.get_variable('pembedding', [self.position_vocab, self.pos_size])\n","                    self.rembedding = tf.get_variable('rembedding', [self.position_vocab, self.pos_size])\n","                    self.pos_embed = tf.nn.embedding_lookup(self.pembedding, self.encoder_pos)\n","                    self.rpos_embed = tf.nn.embedding_lookup(self.rembedding, self.encoder_rpos)\n","                    if position_concat:\n","                        self.encoder_embed = tf.concat([self.encoder_embed, self.pos_embed, self.rpos_embed], 2)\n","                        self.field_pos_embed = tf.concat([self.field_embed, self.pos_embed, self.rpos_embed], 2)\n","                    elif self.encoder_add_pos or self.decoder_add_pos:\n","                        self.field_pos_embed = tf.concat([self.field_embed, self.pos_embed, self.rpos_embed], 2)\n","\n","        if self.field_concat or self.fgate_enc:\n","            self.params.update({'fembedding': self.fembedding})\n","        if self.position_concat or self.encoder_add_pos or self.decoder_add_pos:\n","            self.params.update({'pembedding': self.pembedding})\n","            self.params.update({'rembedding': self.rembedding})\n","        self.params.update({'embedding': self.embedding})\n","\n","        # ======================================== encoder ======================================== #\n","        if self.fgate_enc:\n","            print( 'field gated encoder used')\n","            en_outputs, en_state = self.fgate_encoder(self.encoder_embed, self.field_pos_embed, self.encoder_len)\n","        else:\n","            print( 'normal encoder used')\n","            en_outputs, en_state = self.encoder(self.encoder_embed, self.encoder_len)\n","        # ======================================== decoder ======================================== #\n","\n","        if self.dual_att:\n","\t        print( 'dual attention mechanism used')\n","\t        with tf.variable_scope(scope_name):\n","\t            self.att_layer = dualAttentionWrapper(self.hidden_size, self.hidden_size, self.field_attention_size,\n","\t                                                    en_outputs, self.field_pos_embed, \"attention\")\n","\t            self.units.update({'attention': self.att_layer})\n","        else:\n","            print( \"normal attention used\")\n","            with tf.variable_scope(scope_name):\n","                self.att_layer = AttentionWrapper(self.hidden_size, self.hidden_size, en_outputs, \"attention\")\n","                self.units.update({'attention': self.att_layer})\n","\n","\n","        # decoder for training\n","        de_outputs, de_state = self.decoder_t(en_state, self.decoder_embed, self.decoder_len)\n","        # decoder for testing\n","        self.g_tokens, self.atts = self.decoder_g(en_state)\n","        # self.beam_seqs, self.beam_probs, self.cand_seqs, self.cand_probs = self.decoder_beam(en_state, beam_size)\n","        \n","\n","        losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=de_outputs, labels=self.decoder_output)\n","        mask = tf.sign(tf.to_float(self.decoder_output))\n","        losses = mask * losses\n","        self.mean_loss = tf.reduce_mean(losses)\n","\n","        tvars = tf.trainable_variables()\n","        grads, _ = tf.clip_by_global_norm(tf.gradients(self.mean_loss, tvars), self.grad_clip)\n","        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","        self.train_op = optimizer.apply_gradients(zip(grads, tvars))\n","\n","    def encoder(self, inputs, inputs_len):\n","        batch_size = tf.shape(self.encoder_input)[0]\n","        max_time = tf.shape(self.encoder_input)[1]\n","        hidden_size = self.hidden_size\n","\n","        time = tf.constant(0, dtype=tf.int32)\n","        h0 = (tf.zeros([batch_size, hidden_size], dtype=tf.float32),\n","              tf.zeros([batch_size, hidden_size], dtype=tf.float32))\n","        f0 = tf.zeros([batch_size], dtype=tf.bool)\n","        inputs_ta = tf.TensorArray(dtype=tf.float32, size=max_time)\n","        inputs_ta = inputs_ta.unstack(tf.transpose(inputs, [1,0,2]))\n","        emit_ta = tf.TensorArray(dtype=tf.float32, dynamic_size=True, size=0)\n","\n","        def loop_fn(t, x_t, s_t, emit_ta, finished):\n","            o_t, s_nt = self.enc_lstm(x_t, s_t, finished)\n","            emit_ta = emit_ta.write(t, o_t)\n","            finished = tf.greater_equal(t+1, inputs_len)\n","            x_nt = tf.cond(tf.reduce_all(finished), lambda: tf.zeros([batch_size, self.uni_size], dtype=tf.float32),\n","                                     lambda: inputs_ta.read(t+1))\n","            return t+1, x_nt, s_nt, emit_ta, finished\n","\n","        _, _, state, emit_ta, _ = tf.while_loop(\n","            cond=lambda _1, _2, _3, _4, finished: tf.logical_not(tf.reduce_all(finished)),\n","            body=loop_fn,\n","            loop_vars=(time, inputs_ta.read(0), h0, emit_ta, f0))\n","\n","        outputs = tf.transpose(emit_ta.stack(), [1,0,2])\n","        return outputs, state\n","\n","    def fgate_encoder(self, inputs, fields, inputs_len):\n","        batch_size = tf.shape(self.encoder_input)[0]\n","        max_time = tf.shape(self.encoder_input)[1]\n","        hidden_size = self.hidden_size\n","\n","        time = tf.constant(0, dtype=tf.int32)\n","        h0 = (tf.zeros([batch_size, hidden_size], dtype=tf.float32),\n","              tf.zeros([batch_size, hidden_size], dtype=tf.float32))\n","        f0 = tf.zeros([batch_size], dtype=tf.bool)\n","        inputs_ta = tf.TensorArray(dtype=tf.float32, size=max_time)\n","        inputs_ta = inputs_ta.unstack(tf.transpose(inputs, [1,0,2]))\n","        fields_ta = tf.TensorArray(dtype=tf.float32, size=max_time)\n","        fields_ta = fields_ta.unstack(tf.transpose(fields, [1,0,2]))\n","        emit_ta = tf.TensorArray(dtype=tf.float32, dynamic_size=True, size=0)\n","\n","        def loop_fn(t, x_t, d_t, s_t, emit_ta, finished):\n","            o_t, s_nt = self.enc_lstm(x_t, d_t, s_t, finished)\n","            emit_ta = emit_ta.write(t, o_t)\n","            finished = tf.greater_equal(t+1, inputs_len)\n","            x_nt = tf.cond(tf.reduce_all(finished), lambda: tf.zeros([batch_size, self.uni_size], dtype=tf.float32),\n","                                     lambda: inputs_ta.read(t+1))\n","            d_nt = tf.cond(tf.reduce_all(finished), lambda: tf.zeros([batch_size, self.field_attention_size], dtype=tf.float32),\n","                                     lambda: fields_ta.read(t+1))\n","            return t+1, x_nt, d_nt, s_nt, emit_ta, finished\n","\n","        _, _, _, state, emit_ta, _ = tf.while_loop(\n","            cond=lambda _1, _2, _3, _4, _5, finished: tf.logical_not(tf.reduce_all(finished)),\n","            body=loop_fn,\n","            loop_vars=(time, inputs_ta.read(0), fields_ta.read(0), h0, emit_ta, f0))\n","\n","        outputs = tf.transpose(emit_ta.stack(), [1,0,2])\n","        return outputs, state\n","\n","\n","    def decoder_t(self, initial_state, inputs, inputs_len):\n","        batch_size = tf.shape(self.decoder_input)[0]\n","        max_time = tf.shape(self.decoder_input)[1]\n","        encoder_len = tf.shape(self.encoder_input)[1]\n","\n","        time = tf.constant(0, dtype=tf.int32)\n","        h0 = initial_state\n","        f0 = tf.zeros([batch_size], dtype=tf.bool)\n","        x0 = tf.nn.embedding_lookup(self.embedding, tf.fill([batch_size], self.start_token))\n","        inputs_ta = tf.TensorArray(dtype=tf.float32, size=max_time)\n","        inputs_ta = inputs_ta.unstack(tf.transpose(inputs, [1,0,2]))\n","        emit_ta = tf.TensorArray(dtype=tf.float32, dynamic_size=True, size=0)\n","\n","        def loop_fn(t, x_t, s_t, emit_ta, finished):\n","            o_t, s_nt = self.dec_lstm(x_t, s_t, finished)\n","            o_t, _ = self.att_layer(o_t)\n","            o_t = self.dec_out(o_t, finished)\n","            emit_ta = emit_ta.write(t, o_t)\n","            finished = tf.greater_equal(t, inputs_len)\n","            x_nt = tf.cond(tf.reduce_all(finished), lambda: tf.zeros([batch_size, self.emb_size], dtype=tf.float32),\n","                                     lambda: inputs_ta.read(t))\n","            return t+1, x_nt, s_nt, emit_ta, finished\n","\n","        _, _, state, emit_ta,  _ = tf.while_loop(\n","            cond=lambda _1, _2, _3, _4, finished: tf.logical_not(tf.reduce_all(finished)),\n","            body=loop_fn,\n","            loop_vars=(time, x0, h0, emit_ta, f0))\n","\n","        outputs = tf.transpose(emit_ta.stack(), [1,0,2])\n","        return outputs, state\n","\n","    def decoder_g(self, initial_state):\n","        batch_size = tf.shape(self.encoder_input)[0]\n","        encoder_len = tf.shape(self.encoder_input)[1]\n","\n","        time = tf.constant(0, dtype=tf.int32)\n","        h0 = initial_state\n","        f0 = tf.zeros([batch_size], dtype=tf.bool)\n","        x0 = tf.nn.embedding_lookup(self.embedding, tf.fill([batch_size], self.start_token))\n","        emit_ta = tf.TensorArray(dtype=tf.float32, dynamic_size=True, size=0)\n","        att_ta = tf.TensorArray(dtype=tf.float32, dynamic_size=True, size=0)\n","\n","        def loop_fn(t, x_t, s_t, emit_ta, att_ta, finished):\n","            o_t, s_nt = self.dec_lstm(x_t, s_t, finished)\n","            o_t, w_t = self.att_layer(o_t)\n","            o_t = self.dec_out(o_t, finished)\n","            emit_ta = emit_ta.write(t, o_t)\n","            att_ta = att_ta.write(t, w_t)\n","            next_token = tf.arg_max(o_t, 1)\n","            x_nt = tf.nn.embedding_lookup(self.embedding, next_token)\n","            finished = tf.logical_or(finished, tf.equal(next_token, self.stop_token))\n","            finished = tf.logical_or(finished, tf.greater_equal(t, self.max_length))\n","            return t+1, x_nt, s_nt, emit_ta, att_ta, finished\n","\n","        _, _, state, emit_ta, att_ta, _ = tf.while_loop(\n","            cond=lambda _1, _2, _3, _4, _5, finished: tf.logical_not(tf.reduce_all(finished)),\n","            body=loop_fn,\n","            loop_vars=(time, x0, h0, emit_ta, att_ta, f0))\n","\n","        outputs = tf.transpose(emit_ta.stack(), [1,0,2])\n","        pred_tokens = tf.arg_max(outputs, 2)\n","        atts = att_ta.stack()\n","        return pred_tokens, atts\n","\n","\n","    def decoder_beam(self, initial_state, beam_size):\n","\n","        def beam_init():\n","            # return beam_seqs_1 beam_probs_1 cand_seqs_1 cand_prob_1 next_states time\n","            time_1 = tf.constant(1, dtype=tf.int32)\n","            beam_seqs_0 = tf.constant([[self.start_token]]*beam_size)\n","            beam_probs_0 = tf.constant([0.]*beam_size)\n","\n","            cand_seqs_0 = tf.constant([[self.start_token]])\n","            cand_probs_0 = tf.constant([-3e38])\n","\n","            beam_seqs_0._shape = tf.TensorShape((None, None))\n","            beam_probs_0._shape = tf.TensorShape((None,))\n","            cand_seqs_0._shape = tf.TensorShape((None, None))\n","            cand_probs_0._shape = tf.TensorShape((None,))\n","            \n","            inputs = [self.start_token]\n","            x_t = tf.nn.embedding_lookup(self.embedding, inputs)\n","            print(x_t.get_shape().as_list())\n","            o_t, s_nt = self.dec_lstm(x_t, initial_state)\n","            o_t, w_t = self.att_layer(o_t)\n","            o_t = self.dec_out(o_t)\n","            print(s_nt[0].get_shape().as_list())\n","            # initial_state = tf.reshape(initial_state, [1,-1])\n","            logprobs2d = tf.nn.log_softmax(o_t)\n","            total_probs = logprobs2d + tf.reshape(beam_probs_0, [-1, 1])\n","            total_probs_noEOS = tf.concat([tf.slice(total_probs, [0, 0], [1, self.stop_token]),\n","                               tf.tile([[-3e38]], [1, 1]),\n","                               tf.slice(total_probs, [0, self.stop_token + 1],\n","                                        [1, self.target_vocab - self.stop_token - 1])], 1)\n","            flat_total_probs = tf.reshape(total_probs_noEOS, [-1])\n","            print (flat_total_probs.get_shape().as_list())\n","\n","            beam_k = tf.minimum(tf.size(flat_total_probs), beam_size)\n","            next_beam_probs, top_indices = tf.nn.top_k(flat_total_probs, k=beam_k)\n","\n","            next_bases = tf.floordiv(top_indices, self.target_vocab)\n","            next_mods = tf.mod(top_indices, self.target_vocab)\n","\n","            next_beam_seqs = tf.concat([tf.gather(beam_seqs_0, next_bases),\n","                                        tf.reshape(next_mods, [-1, 1])], 1)\n","\n","            cand_seqs_pad = tf.pad(cand_seqs_0, [[0, 0], [0, 1]])\n","            beam_seqs_EOS = tf.pad(beam_seqs_0, [[0, 0], [0, 1]])\n","            new_cand_seqs = tf.concat([cand_seqs_pad, beam_seqs_EOS], 0)\n","            print (new_cand_seqs.get_shape().as_list())\n","\n","            EOS_probs = tf.slice(total_probs, [0, self.stop_token], [beam_size, 1])\n","            new_cand_probs = tf.concat([cand_probs_0, tf.reshape(EOS_probs, [-1])], 0)\n","            cand_k = tf.minimum(tf.size(new_cand_probs), self.beam_size)\n","            next_cand_probs, next_cand_indices = tf.nn.top_k(new_cand_probs, k=cand_k)\n","            next_cand_seqs = tf.gather(new_cand_seqs, next_cand_indices)\n","\n","            part_state_0 = tf.reshape(tf.stack([s_nt[0]]*beam_size), [beam_size, self.hidden_size])\n","            part_state_1 = tf.reshape(tf.stack([s_nt[1]]*beam_size), [beam_size, self.hidden_size])\n","            part_state_0._shape = tf.TensorShape((None, None))\n","            part_state_1._shape = tf.TensorShape((None, None))\n","            next_states = (part_state_0, part_state_1)\n","            print (next_states[0].get_shape().as_list())\n","            return next_beam_seqs, next_beam_probs, next_cand_seqs, next_cand_probs, next_states, time_1\n","\n","        beam_seqs_1, beam_probs_1, cand_seqs_1, cand_probs_1, states_1, time_1 = beam_init()\n","        beam_seqs_1._shape = tf.TensorShape((None, None))\n","        beam_probs_1._shape = tf.TensorShape((None,))\n","        cand_seqs_1._shape = tf.TensorShape((None, None))\n","        cand_probs_1._shape = tf.TensorShape((None,))\n","        # states_1._shape = tf.TensorShape((2, None, self.hidden_size))\n","        def beam_step(beam_seqs, beam_probs, cand_seqs, cand_probs, states, time):\n","            '''\n","            beam_seqs : [beam_size, time]\n","            beam_probs: [beam_size, ]\n","            cand_seqs : [beam_size, time]\n","            cand_probs: [beam_size, ]\n","            states : [beam_size * hidden_size, beam_size * hidden_size]\n","            '''\n","            inputs = tf.reshape(tf.slice(beam_seqs, [0, time], [beam_size, 1]), [beam_size])\n","            # print inputs.get_shape().as_list()\n","            x_t = tf.nn.embedding_lookup(self.embedding, inputs)\n","            # print(x_t.get_shape().as_list())\n","            o_t, s_nt = self.dec_lstm(x_t, states)\n","            o_t, w_t = self.att_layer(o_t)\n","            o_t = self.dec_out(o_t)\n","            logprobs2d = tf.nn.log_softmax(o_t)\n","            print (logprobs2d.get_shape().as_list())\n","            total_probs = logprobs2d + tf.reshape(beam_probs, [-1, 1])\n","            print (total_probs.get_shape().as_list())\n","            total_probs_noEOS = tf.concat([tf.slice(total_probs, [0, 0], [beam_size, self.stop_token]),\n","                                           tf.tile([[-3e38]], [beam_size, 1]),\n","                                           tf.slice(total_probs, [0, self.stop_token + 1],\n","                                                    [beam_size, self.target_vocab - self.stop_token - 1])], 1)\n","            print (total_probs_noEOS.get_shape().as_list())\n","            flat_total_probs = tf.reshape(total_probs_noEOS, [-1])\n","            print (flat_total_probs.get_shape().as_list())\n","\n","            beam_k = tf.minimum(tf.size(flat_total_probs), beam_size)\n","            next_beam_probs, top_indices = tf.nn.top_k(flat_total_probs, k=beam_k)\n","            print (next_beam_probs.get_shape().as_list())\n","\n","            next_bases = tf.floordiv(top_indices, self.target_vocab)\n","            next_mods = tf.mod(top_indices, self.target_vocab)\n","            print (next_mods.get_shape().as_list())\n","\n","            next_beam_seqs = tf.concat([tf.gather(beam_seqs, next_bases),\n","                                        tf.reshape(next_mods, [-1, 1])], 1)\n","            next_states = (tf.gather(s_nt[0], next_bases), tf.gather(s_nt[1], next_bases))\n","            print (next_beam_seqs.get_shape().as_list())\n","\n","            cand_seqs_pad = tf.pad(cand_seqs, [[0, 0], [0, 1]])\n","            beam_seqs_EOS = tf.pad(beam_seqs, [[0, 0], [0, 1]])\n","            new_cand_seqs = tf.concat([cand_seqs_pad, beam_seqs_EOS], 0) \n","            print (new_cand_seqs.get_shape().as_list())\n","\n","            EOS_probs = tf.slice(total_probs, [0, self.stop_token], [beam_size, 1])\n","            new_cand_probs = tf.concat([cand_probs, tf.reshape(EOS_probs, [-1])], 0)\n","            cand_k = tf.minimum(tf.size(new_cand_probs), self.beam_size)\n","            next_cand_probs, next_cand_indices = tf.nn.top_k(new_cand_probs, k=cand_k)\n","            next_cand_seqs = tf.gather(new_cand_seqs, next_cand_indices)\n","\n","            return next_beam_seqs, next_beam_probs, next_cand_seqs, next_cand_probs, next_states, time+1\n","        \n","        def beam_cond(beam_probs, beam_seqs, cand_probs, cand_seqs, state, time):\n","            length =  (tf.reduce_max(beam_probs) >= tf.reduce_min(cand_probs))\n","            return tf.logical_and(length, tf.less(time, 60) )\n","            # return tf.less(time, 18)\n","\n","        loop_vars = [beam_seqs_1, beam_probs_1, cand_seqs_1, cand_probs_1, states_1, time_1]\n","        ret_vars = tf.while_loop(cond=beam_cond, body=beam_step, loop_vars=loop_vars, back_prop=False)\n","        beam_seqs_all, beam_probs_all, cand_seqs_all, cand_probs_all, _, time_all = ret_vars\n","\n","        return beam_seqs_all, beam_probs_all, cand_seqs_all, cand_probs_all\n","\n","    def __call__(self, x, sess):\n","        loss,  _ = sess.run([self.mean_loss, self.train_op],\n","                           {self.encoder_input: x['enc_in'], self.encoder_len: x['enc_len'], \n","                            self.encoder_field: x['enc_fd'], self.encoder_pos: x['enc_pos'], \n","                            self.encoder_rpos: x['enc_rpos'], self.decoder_input: x['dec_in'],\n","                            self.decoder_len: x['dec_len'], self.decoder_output: x['dec_out']})\n","        return loss\n","\n","    def generate(self, x, sess):\n","        predictions, atts = sess.run([self.g_tokens, self.atts],\n","                               {self.encoder_input: x['enc_in'], self.encoder_field: x['enc_fd'], \n","                                self.encoder_len: x['enc_len'], self.encoder_pos: x['enc_pos'],\n","                                self.encoder_rpos: x['enc_rpos']})\n","        return predictions, atts\n","\n","    def generate_beam(self, x, sess):\n","        # beam_seqs_all, beam_probs_all, cand_seqs_all, cand_probs_all\n","        beam_seqs_all, beam_probs_all, cand_seqs_all, cand_probs_all = sess.run(\n","                         [self.beam_seqs,self.beam_probs, self.cand_seqs, self.cand_probs],\n","                         {self.encoder_input: x['enc_in'], self.encoder_field: x['enc_fd'],\n","                          self.encoder_len: x['enc_len'], self.encoder_pos: x['enc_pos'],\n","                          self.encoder_rpos: x['enc_rpos']})\n","        return beam_seqs_all, beam_probs_all, cand_seqs_all, cand_probs_all\n","\n","    def save(self, path):\n","        for u in self.units:\n","            self.units[u].save(path+u+\".pkl\")\n","        param_values = {}\n","        for param in self.params:\n","            param_values[param] = self.params[param].eval()\n","        with open(path+self.name+\".pkl\", 'wb') as f:\n","            pickle.dump(param_values, f, True)\n","\n","    def load(self, path):\n","        for u in self.units:\n","            self.units[u].load(path+u+\".pkl\")\n","        param_values = pickle.load(open(path+self.name+\".pkl\", 'rb'))\n","        for param in param_values:\n","            self.params[param].load(param_values[param])"],"execution_count":2,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-224548c8d1f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mAttentionUnit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAttentionWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdualAttentionUnit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdualAttentionWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mLstmUnit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLstmUnit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'AttentionUnit'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]}]}