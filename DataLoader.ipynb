{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DataLoader.ipynb","provenance":[],"authorship_tag":"ABX9TyMIkoUEiiJD0nR0xUVZ4+FL"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"hb8updptSKzg","colab_type":"code","colab":{}},"source":["#!/usr/bin/env python\n","# -*- coding: utf-8 -*-\n","# @Time    : 17-4-27 下午8:43\n","# @Author  : Tianyu Liu\n","\n","import tensorflow as tf\n","import time\n","import numpy as np\n","\n","\n","class DataLoader(object):\n","    def __init__(self, data_dir, limits):\n","        self.train_data_path = [data_dir + '/train/train.summary.id', data_dir + '/train/train.box.val.id',\n","                                data_dir + '/train/train.box.lab.id', data_dir + '/train/train.box.pos',\n","                                data_dir + '/train/train.box.rpos']\n","        self.test_data_path = [data_dir + '/test/test.summary.id', data_dir + '/test/test.box.val.id',\n","                               data_dir + '/test/test.box.lab.id', data_dir + '/test/test.box.pos',\n","                               data_dir + '/test/test.box.rpos']\n","        self.dev_data_path = [data_dir + '/valid/valid.summary.id', data_dir + '/valid/valid.box.val.id',\n","                              data_dir + '/valid/valid.box.lab.id', data_dir + '/valid/valid.box.pos',\n","                              data_dir + '/valid/valid.box.rpos']\n","        self.limits = limits\n","        self.man_text_len = 100\n","        start_time = time.time()\n","\n","        print('Reading datasets ...')\n","        self.train_set = self.load_data(self.train_data_path)\n","        self.test_set = self.load_data(self.test_data_path)\n","        # self.small_test_set = self.load_data(self.small_test_data_path)\n","        self.dev_set = self.load_data(self.dev_data_path)\n","        print ('Reading datasets comsumes %.3f seconds' % (time.time() - start_time))\n","\n","    def load_data(self, path):\n","        summary_path, text_path, field_path, pos_path, rpos_path = path\n","        summaries = open(summary_path, 'r').read().strip().split('\\n')\n","        texts = open(text_path, 'r').read().strip().split('\\n')\n","        fields = open(field_path, 'r').read().strip().split('\\n')\n","        poses = open(pos_path, 'r').read().strip().split('\\n')\n","        rposes = open(rpos_path, 'r').read().strip().split('\\n')\n","        if self.limits > 0:\n","            summaries = summaries[:self.limits]\n","            texts = texts[:self.limits]\n","            fields = fields[:self.limits]\n","            poses = poses[:self.limits]\n","            rposes = rposes[:self.limits]\n","        print (summaries[0].strip().split(' '))\n","        summaries = [list(map(int, summary.strip().split(' '))) for summary in summaries]\n","        texts = [list(map(int, text.strip().split(' '))) for text in texts]\n","        fields = [list(map(int, field.strip().split(' '))) for field in fields]\n","        poses = [list(map(int, pos.strip().split(' '))) for pos in poses]\n","        rposes = [list(map(int, rpos.strip().split(' '))) for rpos in rposes]\n","        return summaries, texts, fields, poses, rposes\n","\n","    def batch_iter(self, data, batch_size, shuffle):\n","        summaries, texts, fields, poses, rposes = data\n","        data_size = len(summaries)\n","        num_batches = int(data_size / batch_size) if data_size % batch_size == 0 \\\n","            else int(data_size / batch_size) + 1\n","\n","        if shuffle:\n","            shuffle_indices = np.random.permutation(np.arange(data_size))\n","            summaries = np.array(summaries)[shuffle_indices]\n","            texts = np.array(texts)[shuffle_indices]\n","            fields = np.array(fields)[shuffle_indices]\n","            poses = np.array(poses)[shuffle_indices]\n","            rposes = np.array(rposes)[shuffle_indices]\n","\n","        for batch_num in range(num_batches):\n","            start_index = batch_num * batch_size\n","            end_index = min((batch_num + 1) * batch_size, data_size)\n","            max_summary_len = max([len(sample) for sample in summaries[start_index:end_index]])\n","            max_text_len = max([len(sample) for sample in texts[start_index:end_index]])\n","            batch_data = {'enc_in':[], 'enc_fd':[], 'enc_pos':[], 'enc_rpos':[], 'enc_len':[],\n","                          'dec_in':[], 'dec_len':[], 'dec_out':[]}\n","\n","            for summary, text, field, pos, rpos in zip(summaries[start_index:end_index], texts[start_index:end_index],\n","                                            fields[start_index:end_index], poses[start_index:end_index],\n","                                            rposes[start_index:end_index]):\n","                summary_len = len(summary)\n","                text_len = len(text)\n","                pos_len = len(pos)\n","                rpos_len = len(rpos)\n","                assert text_len == len(field)\n","                assert pos_len == len(field)\n","                assert rpos_len == pos_len\n","                gold = summary + [2] + [0] * (max_summary_len - summary_len)\n","                summary = summary + [0] * (max_summary_len - summary_len)\n","                text = text + [0] * (max_text_len - text_len)\n","                field = field + [0] * (max_text_len - text_len)\n","                pos = pos + [0] * (max_text_len - text_len)\n","                rpos = rpos + [0] * (max_text_len - text_len)\n","                \n","                if max_text_len > self.man_text_len:\n","                    text = text[:self.man_text_len]\n","                    field = field[:self.man_text_len]\n","                    pos = pos[:self.man_text_len]\n","                    rpos = rpos[:self.man_text_len]\n","                    text_len = min(text_len, self.man_text_len)\n","                \n","                batch_data['enc_in'].append(text)\n","                batch_data['enc_len'].append(text_len)\n","                batch_data['enc_fd'].append(field)\n","                batch_data['enc_pos'].append(pos)\n","                batch_data['enc_rpos'].append(rpos)\n","                batch_data['dec_in'].append(summary)\n","                batch_data['dec_len'].append(summary_len)\n","                batch_data['dec_out'].append(gold)\n","  \n","            yield batch_data"],"execution_count":0,"outputs":[]}]}